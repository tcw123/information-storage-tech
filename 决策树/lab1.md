<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# lab1《机器学习》4.3 基于信息熵进行划分的决策树算法
## 信息熵
信息熵时信息的度量方式，不确定度越大（越混乱），熵越大，
信息熵计算公式：$$\{H\text{ }=\text{ }-{\mathop{ \sum }\limits_{{i=1}}^{{n}}{p{ \left( {\mathop{{x}}\nolimits_{{i}}} \right) }\mathop{{log}}\nolimits_{{2}}{ \left( {p{ \left( {\mathop{{x}}\nolimits_{{i}}} \right) }} \right) }}}}\$$

## 信息增益
两个信息熵的差值

## 决策树
一种分类方法，属于监督学习

核心思想：在一个数据集中找到一个最优特征，然后从这个特征的选值中找一个最优候选值，根据这个最优候选值将数据集分为两个子数据集，然后递归上述操作，直到满足指定条件为止。

常见算法：ID3、C4.5、CART

## 基于信息熵的决策树算法
```
1.计算出分类前的熵
2.分别计算出使用不同方案分类后的熵
3.分别计算各种方案的信息增益，信息增益大的即为最佳分类特征
信息增益越大，代表分类后熵更低，区分样本的能力更强，更具有代表性
```
### ID3算法（迭代二分法，Iterative Dichotomiser 3）
基于贪心策略，每次分支选择熵减少最大的特征来划分-“最大信息熵增益”原则

对于本实验，在`boyorgirl.py`增加了连续值的处理函数。通过将连续值排序后，使用二分法依次迭代，找到可以达到“最大信息熵增益”的划分。

### [boyorgirl.py](./boyorgirl.py)
- zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。
```python
>>> a = [1,2,3]
>>> b = [4,5,6]
>>> c = [4,5,6,7,8]
>>> zipped = zip(a,b)     # 打包为元组的列表
[(1, 4), (2, 5), (3, 6)]
>>> zip(a,c)              # 元素个数与最短的列表一致
[(1, 4), (2, 5), (3, 6)]
>>> zip(*zipped)          # 与 zip 相反，*zipped 可理解为解压，返回二维矩阵式
[(1, 2, 3), (4, 5, 6)]
```